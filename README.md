# Neural Network Models for Non-Linear Regression

This project encompasses the development of a three-layer neural network designed to tackle non-linear regression problems. The implementations span across different frameworks and methodologies, from manual computations using Numpy to advanced model definitions with TensorFlow and JAX. This README outlines the structure of the project, including brief descriptions of each model and instructions for replication.


> ## Video Link: [Click Here](https://youtu.be/iQYjSWzYlPs)
## Project Structure

The project is divided into eight distinct implementations, each utilizing a different approach or framework to achieve the goal of non-linear regression. Below is an overview of these implementations:

### a) Numpy Only - Manual Implementation
- **Framework**: Numpy
- **Features**: Manual forward pass, backward pass, and parameter update steps.


### b) PyTorch From Scratch
- **Framework**: PyTorch
- **Features**: Utilizes PyTorch's tensor operations without high-level abstractions for model definition and training.


### c) PyTorch with Built-in Classes
- **Framework**: PyTorch
- **Features**: Leverages PyTorch's nn.Module and other high-level abstractions.


### d) PyTorch Lightning
- **Framework**: PyTorch Lightning
- **Features**: Simplifies the codebase by abstracting the training loop and other boilerplate code.


### e) TensorFlow Low-Level Implementation
- **Framework**: TensorFlow
- **Features**: Focuses on TensorFlow's low-level APIs for detailed control over the model.


### e) TensorFlow with Built-in Layers
- **Framework**: TensorFlow
- **Features**: Implements the model using tf.keras.layers for a more concise definition.


### e) TensorFlow Functional API
- **Framework**: TensorFlow
- **Features**: Uses the Functional API for models that require a greater degree of flexibility.


### h) JAX Implementation
- **Framework**: JAX
- **Features**: Exploits JAX for high-performance computing and automatic differentiation.


# **References Used**:
> [Numpy Only Implementation](https://colab.research.google.com/drive/1HS3qbHArkqFlImT2KnF5pcMCz7ueHNvY?usp=sharing&authuser=1#scrollTo=EGkS6nN6dQaz)

>[PyTorch From Scratch](https://docs.google.com/presentation/d/13Oo5gXwcsoq9oMC4XriAyxkvgicatBxfI4cZzDhRyiE/edit#slide=id.g826a355833_0_525)

>[PyTorch with Built-in Classes](https://colab.research.google.com/drive/1HS3qbHArkqFlImT2KnF5pcMCz7ueHNvY?usp=sharing&authuser=1#scrollTo=EGkS6nN6dQaz)

>[PyTorch Lightning Model](https://docs.google.com/presentation/d/13Oo5gXwcsoq9oMC4XriAyxkvgicatBxfI4cZzDhRyiE/edit#slide=id.g826a355833_0_525)

>[TensorFlow Low-Level](https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO?authuser=1#scrollTo=KC5RgwGeBP-9)

>[TensorFlow with Built-in Layers](https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO?authuser=1#scrollTo=SyC7KfV-YcYS)

>[TensorFlow Functional API](https://colab.research.google.com/drive/169PfzM0kvtA5UP4k6Sl1yCG9tsE2MLia?authuser=1#scrollTo=C_2FyZeXjHd1)

>[JAX Model](https://www.tutorialspoint.com/how-to-make-a-4d-plot-with-matplotlib-using-arbitrary-data)
